<!DOCTYPE html>
<html lang="en" dir="ltr">
    <head>
        <link href="css/style.css" rel="stylesheet" type="text/css" media="all">
            <link rel="script" href="js/script.js">
                <link rel="icon" type="image/x-icon" href="img/favicon.ico">
                    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
                        <title>Taishi Nakamura portfolio</title>
                    </head>
    <body>
        <nav>
            <ul>
              <li><a href="#about">About</a></li>
              <li><a href="#education">Education</a></li>
              <li><a href="#research">Research experience</a></li>
              <li><a href="#industrial">Industrial experience</a></li>
              <li><a href="#contact">Contact</a></li>
            </ul>
          </nav>
        <div class="centering-block">
            <div class="centering-block-inner">
                <h1 id="about">Taishi Nakamura</h1>
                <div class="text-container">
                    <p>
                        I love training large-scale models and am interested in scalable neural network architectures. I am also fascinated by the computing power that enables this, including distributed computing and the next generation of computing, quantum computers. I am passionate about building multimodal systems, advanced reasoning, and creating agents that continually evolve.
                    </p>     
                </div>

                <h2 id="education"> Education </h2>

                <h3>Tokyo Institute of Technology</h3>
                <h3>Apr 2024 - Present &nbsp; Tokyo Institute of Technology</h3>
                <div class="logo-text">
                    <img src="./img/tokyotech.webp" alt="Tokyo Tech logo">
                    <div class="text-container">
                        <p>Master of Science in Computer Science</p>
                    </div>
                </div>

                <h3>Apr 2021 - Mar2024 &nbsp; Tokyo Institute of Technology</h3>
                <div class="logo-text">
                    <img src="./img/tokyotech.webp" alt="Tokyo Tech logo">
                    <div class="text-container">
                        <p>Bachelor of Science in Computer Science</p>
                        <p>Graduated one year early due to outstanding academic performance</p>
                    </div>
                </div>

                <h2 id="research">Research experience</h2>

                <h3>Feb 2024 - Present &nbsp; Sakana AI</h3>
                <div class="logo-text">
                    <img src="./img/sakana-ai.jpeg" alt="Sakana AI logo">
                    <div class="text-container">
                        <p>
                            Research Internship
                        </p>
                    </div>
                </div>

                <h3>Sep 2023 - Present &nbsp; TokyoTech-LLM</h3>
                <div class="logo-text">
                    <img src="./img/tokyotech-llm.png" alt="TokyoTech-LLM logo">
                    <div class="text-container">
                        <p>
                            Focus on continual pretraining from strong pretrained models such as the Llama-2 family to develop a strong Japanese model
                        </p>
                        <p>
                            The published model can be found <a href="https://huggingface.co/tokyotech-llm/Swallow-70b-instruct-hf">here</a>.
                        </p>
                        <p>
                            The project link can be found <a href="https://tokyotech-llm.github.io">here</a>.
                        </p>
                    </div>     
                </div>

                <h3>Jun 2023 - Present &nbsp; GPT-Fugaku</h3>
                <div class="logo-text">
                    <img src="./img/gpt-fugaku.png" alt="GPT-Fugaku logo">
                    <div class="text-container">
                        <p>
                            Training Japanese Large Language Models Utilizing Extensive Scale CPUs on Fugaku
                        </p>
                    </div>
                </div>

                <h3>Jun 2023 - Present &nbsp; LLM-JP</h3>
                <div class="logo-text">
                    <img src="./img/llm-jp.png" alt="llm-jp logo">
                    <div class="text-container">
                        <p>
                            Active as a member of the model construction team.
                        </p>
                        <p>
                            The published model can be found <a href="https://huggingface.co/llm-jp/llm-jp-13b-v1.0">here</a>.
                        </p>
                    </div>
                </div>

                <h3>Apr 2023 - Present &nbsp; YOKOTA Laboratory Tokyo Institute of Technology</h3>
                <div class="logo-text">
                    <img src="./img/yokota-lab.png" alt="YOKOTA Laboratory logo">
                    <div class="text-container">
                        <p>
                            I am truly fortunate to be conducting research with Professor <a href="https://www.rio.gsic.titech.ac.jp/en/member/yokota.html">Rio Yokota</a> as my mentor.
                        </p>
                    </div>
                </div>

                <h3>Apr 2022 - Aug 2023 &nbsp; A*Quantum</h3>
                <div class="logo-text">
                    <img src="./img/aq.jpeg" alt="A*Quantum logo">
                    <div class="text-container">
                        <p>
                            Research Internship
                        </p>
                    </div>
                </div>

                <h2 id="industrial">Industrial Experience</h2>

                <h3>Jun 2023 - Feb 2024 &nbsp; MITOU TARGET</h3>
                <div class="logo-text">
                    <img src="./img/mitou-tg.png" alt="MITOU TARGET logo">
                    <div class="text-container">
                        <p>
                            The project link can be found <a href="https://www.ipa.go.jp/jinzai/mitou/target/2023/gaiyou_ty-3.html">here</a>.
                        </p>
                        <p>
                            The deliverables will be published shortly.
                        </p>
                    </div>
                </div>

                <h3>Feb 2022 - Dec 2022 &nbsp; Crystal Method</h3>
                <div class="logo-text">
                    <img src="./img/crystal.jpeg" alt="crystal method logo">
                    <div class="text-container">
                        <p>
                            Engineering Internship
                        </p>
                    </div>
                </div>

                <h2>Open Source Projects </h2>

                <h3>Oct 2023 - Present &nbsp; Hummingbird</h3>
                <div class="logo-text">
                    <img src="./img/hummingbird.png" alt="Hummingbird logo">
                    <div class="text-container">
                        <p>
                            We will be training models with multimodality.
                        </p>
                    </div>
                </div>

                <h3>Jun 2023 - Present &nbsp; MDEL</h3>
                <div class="logo-text">
                    <img src="./img/mdel.jpeg" alt="MDEL logo">
                    <div class="text-container">
                        <p>
                            I have trained the model and made it publicly available on Hugging Face. 
                        </p>
                        <p>
                            The published model can be found <a href="https://huggingface.co/aurora-m/aurora-m-v0.1">here</a>.
                        </p>
                    </div>
                </div>

                <h2>Preprints</h2>

                <h3>Under review, 2024 &nbsp; Continual Pre-Training for Cross-Lingual LLM Adaptation: Enhancing Japanese Language Capabilities</h3>
                <div class="paper-info">
                        <p>
                            Kazuki Fujii∗, <b>Taishi Nakamura∗</b>, Mengsay Loem, Hiroki Iida, Masanari Ohi, Kakeru Hattori, Hirai Shota, Sakae Mizuki, Rio Yokota, Naoaki Okazaki
                            <a href="https://arxiv.org/abs/2404.17790" target="_blank"><i class="fa fa-file-pdf-o" aria-hidden="true"></i></a>
                        </p>
                </div>

                <h3>Under review, 2024 &nbsp; Building a Large Japanese Web Corpus for Large Language Models</h3>
                <div class="paper-info">
                        <p>
                            Naoaki Okazaki, Kakeru Hattori, Hirai Shota, Hiroki Iida, Masanari Ohi, Kazuki Fujii, <b>Taishi Nakamura</b>, Mengsay Loem, Rio Yokota, Sakae Mizuki
                            <a href="https://arxiv.org/abs/2404.17733" target="_blank"><i class="fa fa-file-pdf-o" aria-hidden="true"></i></a>
                        </p>
                </div>


                <h3>Under review, 2024 &nbsp; Aurora-M: The First Open Source Multilingual Language Model Red-teamed according to the U.S. Executive Order</h3>
                <div class="paper-info">
                        <p>
                            <b>Taishi Nakamura</b>, Mayank Mishra, Simone Tedeschi, Yekun Chai, Jason T Stillerman, Felix Friedrich, Prateek Yadav, Tanmay Laud, Vu Minh Chien, Terry Yue Zhuo, Diganta Misra, Ben Bogin, Xuan-Son Vu, Marzena Karpinska, Arnav Varma Dantuluri, Wojciech Kusa, Tommaso Furlanello, Rio Yokota, Niklas Muennighoff, Suhas Pai, Tosin Adewumi, Veronika Laippala, Xiaozhe Yao, Adalberto Junior, Alpay Ariyak, Aleksandr Drozd, Jordan Clive, Kshitij Gupta, Liangyu Chen, Qi Sun, Ken Tsui, Noah Persaud, Nour Fahmy, Tianlong Chen, Mohit Bansal, Nicolo Monti, Tai Dang, Ziyang Luo, Tien-Tung Bui, Roberto Navigli, Virendra Mehta, Matthew Blumberg, Victor May, Huu Nguyen, Sampo Pyysalo
                            <a href="https://arxiv.org/abs/2404.00399" target="_blank"><i class="fa fa-file-pdf-o" aria-hidden="true"></i></a>
                        </p>
                </div>

                <h2>Domestic Conference in Japan</h2>

                <h3>NLP 2024 &nbsp; 継続事前学習による日本語に強い大規模言語モデルの構築</h3>
                <div class="paper-info">
                        <p>
                            藤井一喜∗, <b>中村泰士∗</b>, Mengsay Loem, 飯田大貴, 大井聖也, 服部翔, 平井翔太, 水木栄, 横田理央, 岡崎直観
                            <a href="https://www.anlp.jp/proceedings/annual_meeting/2024/pdf_dir/A8-5.pdf" target="_blank"><i class="fa fa-file-pdf-o" aria-hidden="true"></i></a>
                        </p>
                </div>

                <h3>NLP 2024  &nbsp; 大規模言語モデルの日本語能力の効率的な強化: 継続事前学習における語彙拡張と対訳コーパスの活用</h3>
                <div class="paper-info">
                        <p>
                            水木栄, 飯田大貴, 藤井一喜, <b>中村泰士</b>, Mengsay Loem, 大井聖也, 服部翔, 平井翔太, 横田理央, 岡崎直観
                            <a href="https://www.anlp.jp/proceedings/annual_meeting/2024/pdf_dir/A6-4.pdf" target="_blank"><i class="fa fa-file-pdf-o" aria-hidden="true"></i></a>
                        </p>
                </div>

                <h3>NLP 2024 &nbsp; Swallowコーパス: 日本語大規模ウェブコーパス</h3>
                <div class="paper-info">
                        <p>
                            岡崎直観, 服部翔, 平井翔太, 飯田大貴, 大井聖也, 藤井一喜, <b>中村泰士</b>, Mengsay Loem, 横田理央, 水木栄
                            <a href="https://www.anlp.jp/proceedings/annual_meeting/2024/pdf_dir/A6-1.pdf" target="_blank"><i class="fa fa-file-pdf-o" aria-hidden="true"></i></a>
                        </p>
                </div>

                <h2 id="contact"> Contact </h2>
                <a href="https://twitter.com/Setuna7777_2" target="_blank" rel="noreferrer" class="sns"><img src="https://raw.githubusercontent.com/danielcranney/readme-generator/main/public/icons/socials/twitter.svg" width="32" height="32" /></a>
                <a href="https://www.github.com/Taishi-N324" target="_blank" rel="noreferrer"><img src="https://raw.githubusercontent.com/danielcranney/readme-generator/main/public/icons/socials/github.svg" width="32" height="32" /></a>
                <a href="https://www.linkedin.com/in/taishi-nakamura" target="_blank" rel="noreferrer"><img src="https://raw.githubusercontent.com/danielcranney/readme-generator/main/public/icons/socials/linkedin.svg" width="32" height="32" /></a>                 
                <P></p>
                <br>Last updated: May 2024
            </div>
        </div>
    </body>
</html>


