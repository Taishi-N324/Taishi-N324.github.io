<!DOCTYPE html>
<html lang="en" dir="ltr">
    <head>
        <link href="css/style.css" rel="stylesheet" type="text/css" media="all">
            <link rel="script" href="js/script.js">
                <link rel="icon" type="image/x-icon" href="img/favicon.ico">
                    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
                        <title>Taishi Nakamura portfolio</title>
                    </head>
    <body>
        <nav>
            <ul>
              <li><a href="#about">About</a></li>
              <li><a href="#education">Education</a></li>
              <li><a href="#research">Research experience</a></li>
              <li><a href="#industrial">Industrial experience</a></li>
              <li><a href="#publications">Publications</a></li>
              <li><a href="#contact">Contact</a></li>
            </ul>
          </nav>
        <div class="centering-block">
            <div class="centering-block-inner">
                <div class="profile-header">
                    <img src="./img/profile.jpg" alt="Taishi Nakamura" class="profile-image">
                    <div class="profile-info">
                        <h1 id="about">Taishi Nakamura</h1>
                        <div class="text-container">
                            <p>
                                I love training large-scale models and am passionate about scalable neural network architectures. I am fascinated by the computing power that enables this, particularly distributed computing systems. My interests extend to building multimodal systems, developing advanced reasoning capabilities, and creating agents that continually evolve. 
                            </p>     
                        </div>
                    </div>
                </div>

                <h2 id="education"> Education </h2>

                <h3>Oct 2024 - Present &nbsp; Institute of Science Tokyo</h3>
                    <div class="logo-text">
                        <img src="./img/science-tokyo.jpg" alt="Institute of Science Tokyo logo">
                        <div class="text-container">
                            <p>Master of Science in Computer Science</p>
                            <p>Supervisor: Professor <a href="https://www.rio.gsic.titech.ac.jp/en/member/yokota.html">Rio Yokota</a></p>
                            <p><i>Note: Formerly Tokyo Institute of Technology, renamed after merging with Tokyo Medical and Dental University in October 2024</i></p>
                        </div>
                    </div>

                    <h3>Apr 2021 - Sep 2024 &nbsp; Tokyo Institute of Technology</h3>
                    <div class="logo-text">
                        <img src="./img/tokyotech.webp" alt="Tokyo Tech logo">
                        <div class="text-container">
                            <p>Master of Science in Computer Science (Apr 2024 - Sep 2024, continued at Institute of Science Tokyo)</p>
                            <p>Bachelor of Science in Computer Science (Apr 2021 - Mar 2024)</p>
                            <p>Supervisor: Professor <a href="https://www.rio.gsic.titech.ac.jp/en/member/yokota.html">Rio Yokota</a></p>
                            <p>Graduated one year early from the bachelor's program due to outstanding academic performance</p>
                        </div>
                    </div>

                <h2 id="research">Research experience</h2>

                <h3>Jun 2024 - Present &nbsp; RIKEN</h3>
                <div class="logo-text">
                    <img src="./img/riken.jpeg" alt="RIKEN logo">
                    <div class="text-container">
                        <p>
                            Research Assistant
                        </p>
                    </div>
                </div>

                <h3>May 2024 - Present &nbsp; NII</h3>
                <div class="logo-text">
                    <img src="./img/nii.jpeg" alt="Sakana AI logo">
                    <div class="text-container">
                        <p>
                            Research Assistant at National Institute of Informatics Large-Scale Language Model Research and Development Center
                        </p>
                        <p>
                            Mentors: Professor <a href="https://www.fai.cds.tohoku.ac.jp/members/js/">Jun Suzuki</a> and Professor <a href="https://www.rio.gsic.titech.ac.jp/en/member/yokota.html">Rio Yokota</a></p>
                        </p>
                    </div>
                </div>

                <h3>Feb 2024 - Present &nbsp; Sakana AI</h3>
                <div class="logo-text">
                    <img src="./img/sakana-ai.jpeg" alt="Sakana AI logo">
                    <div class="text-container">
                        <p>
                            Research Internship
                        </p>
                        <p>
                            Mentor: Dr.  <a href="https://takiba.net/">Takuya Akiba</a> (Research Scientist)</p>
                        </p>
                    </div>
                </div>

                <h3>Oct 2023 - Apr 2024 &nbsp; LLM-JP</h3>
                <div class="logo-text">
                    <img src="./img/llm-jp.png" alt="llm-jp logo">
                    <div class="text-container">
                        <p>
                            Research Internship
                        </p>
                        <p>
                            Active as a member of the Model Building WG
                        </p>
                        <p>
                            Mentor: Professor <a href="https://www.fai.cds.tohoku.ac.jp/members/js/">Jun Suzuki</a></p>
                        </p>
                    </div>
                </div>

                <h3>Apr 2022 - Aug 2023 &nbsp; A*Quantum</h3>
                <div class="logo-text">
                    <img src="./img/aq.jpeg" alt="A*Quantum logo">
                    <div class="text-container">
                        <p>
                            Research Internship
                        </p>
                    </div>
                </div>

                <h2 id="industrial">Industrial Experience</h2>

                <h3>Jun 2023 - Feb 2024 &nbsp; MITOU TARGET</h3>
                <div class="logo-text">
                    <img src="./img/mitou-tg.png" alt="MITOU TARGET logo">
                    <div class="text-container">
                        <p>Selected for the <a href="https://www.ipa.go.jp/en/it-talents/mitou/target-quantum-computing-2023.html">MITOU TARGET program for Quantum Computing</a>.</p>
                        <p>Developed an educational platform for quantum computing, now available at <a href="https://qualsimu.com/textbook/">Qualsimu Textbook</a>.</p>
                        <p>
                            Mentor: Dr.  <a href="https://www.rd.ntt/e/organization/researcher/special/s_023.html">Yuuki Tokunaga</a></p>
                        </p>
                    </div>
                </div>

                <h3>Feb 2022 - Dec 2022 &nbsp; Crystal Method</h3>
                <div class="logo-text">
                    <img src="./img/crystal.jpeg" alt="crystal method logo">
                    <div class="text-container">
                        <p>
                            Engineering Internship
                        </p>
                    </div>
                </div>

                <h2>Open Source Projects </h2>

                <h3>Oct 2023 - Present &nbsp; Swallow LLM</h3>
                    <div class="logo-text">
                        <img src="./img/tokyotech-llm.png" alt="TokyoTech-LLM logo">
                        <div class="text-container">
                            <p>
                                This project contributes to Japan's AI sovereignty efforts and involves collaboration with esteemed researchers including 
                                Professor <a href="https://www.chokkan.org/">Naoaki Okazaki</a>, 
                                Professor <a href="https://www.rio.gsic.titech.ac.jp/en/member/yokota.html">Rio Yokota</a>,
                                and Dr. <a href="https://sites.google.com/view/hjtakamura">Hiroya Takamura</a>.
                            </p>
                            <p>
                                We invite you to explore our progress:
                                <br>
                                â€¢ <a href="https://huggingface.co/tokyotech-llm">View our published models on Hugging Face</a>
                                <br>
                                â€¢ <a href="https://swallow-llm.github.io/index.en.html">Learn more about the project on our website</a>
                            </p>
                        </div>     
                    </div>

                <h3>Jun 2023 - Present &nbsp; Ontocord.AI</h3>
                <div class="logo-text">
                    <img src="./img/ontocord.png" alt="Ontocord.AI logo">
                    <div class="text-container">
                        <p>
                            We've developed Aurora-M, a multilingual model designed to address the challenges of low-resource languages. Our latest release, aurora-m-v0.1-biden-harris-redteamed, is the first open-source multilingual model red-teamed against the Biden-Harris Executive Order on AI.
                        </p>
                        <p>
                            Through these projects, we're actively contributing to the open science community, promoting research that aims to reduce illegal and biased AI outputs while enhancing the utility of AI applications across multiple domains and languages.
                        </p>
                        <p>
                            Explore our work: <a href="https://huggingface.co/aurora-m/aurora-m-v0.1">Aurora-M v0.1 on Hugging Face</a>
                        </p>
                    </div>
                </div>

                <h2 id="publications">Publications</h2>

                <h3>ICLR '2025 (Workshop) &nbsp; Wider or Deeper? Scaling LLM Inference-Time Compute with Adaptive Branching Tree Search</h3>
                <div class="paper-info">
                        <p>
                            Kou Misaki, Yuichi Inoue, Yuki Imajuku, So Kuroki, <b>Taishi Nakamura</b>, Takuya Akiba
                        </p>
                        <p>
                            <a href="https://arxiv.org/abs/2503.04412" target="_blank"><i class="fa fa-file-pdf-o" aria-hidden="true"></i></a>
                        </p>
                </div>

                <h3>ICLR '2025 &nbsp; Drop-Upcycling: Training Sparse Mixture of Experts with Partial Re-initialization</h3>
                <div class="paper-info">
                        <p>
                            <b>Taishi Nakamura</b>, Takuya Akiba, Kazuki Fujii, Yusuke Oda, Rio Yokota, Jun Suzuki
                        </p>
                        <p>
                            <a href="https://openreview.net/forum?id=gx1wHnf5Vp" target="_blank"><i class="fa fa-file-pdf-o" aria-hidden="true"></i></a>
                        </p>
                        <p>
                            Acceptance Rate: 32.08%
                        </p>
                </div>

                <h3>ICLR '2025 &nbsp; Agent Skill Acquisition for Large Language Models via CycleQD</h3>
                <div class="paper-info">
                        <p>
                            So Kuroki, <b>Taishi Nakamura</b>, Takuya Akiba, Yujin Tang
                        </p>
                        <p>
                            <a href="https://arxiv.org/pdf/2410.14735" target="_blank"><i class="fa fa-file-pdf-o" aria-hidden="true"></i></a>
                        </p>
                        <p>
                            Acceptance Rate: 32.08%
                        </p>
                </div>

                <h3>COLING '2025 (Industry Track) &nbsp; Aurora-M: Open Source Continual Pre-training for Multilingual Language and Code
                </h3>
                <div class="paper-info">
                        <p>
                            <b>Taishi Nakamura*</b>, Mayank Mishra*, Simone Tedeschi*, ..., Matthew Blumberg, #Victor May, #Huu Nguyen, #Sampo Pyysalo (49 authors)
                            <a href="https://arxiv.org/abs/2404.00399" target="_blank"><i class="fa fa-file-pdf-o" aria-hidden="true"></i></a>
                        </p>
                        <p>
                            âˆ—Equal contribution #Equal mentoring
                        </p>
                </div>

                <h3>SC '2024 (Workshop) &nbsp; llm-recipes: A Framework for Seamless Integration and Efficient Continual Pre-Training of Large Language Models</h3>
                <div class="paper-info">
                        <p>
                            Kazuki Fujii, <b>Taishi Nakamura</b>, Rio Yokota
                            <a href="https://tpc.dev/tpc-workshop-at-sc24/" target="_blank"><i class="fa fa-file-pdf-o" aria-hidden="true"></i></a>
                        </p>
                </div>

                <h3>COLM '2024 &nbsp; Continual Pre-Training for Cross-Lingual LLM Adaptation: Enhancing Japanese Language Capabilities</h3>
                <div class="paper-info">
                        <p>
                            Kazuki Fujiiâˆ—, <b>Taishi Nakamuraâˆ—</b>, Mengsay Loem, Hiroki Iida, Masanari Ohi, Kakeru Hattori, Hirai Shota, Sakae Mizuki, Rio Yokota, Naoaki Okazaki
                            <a href="https://arxiv.org/abs/2404.17790" target="_blank"><i class="fa fa-file-pdf-o" aria-hidden="true"></i></a>
                        </p>
                        <p>
                            âˆ—Equal contribution
                        </p>
                        <p>
                            Acceptance Rate: 28.8%
                        </p>
                </div>

                <h3>COLM '2024 &nbsp; Building a Large Japanese Web Corpus for Large Language Models</h3>
                <div class="paper-info">
                        <p>
                            Naoaki Okazaki, Kakeru Hattori, Hirai Shota, Hiroki Iida, Masanari Ohi, Kazuki Fujii, <b>Taishi Nakamura</b>, Mengsay Loem, Rio Yokota, Sakae Mizuki
                            <a href="https://arxiv.org/abs/2404.17733" target="_blank"><i class="fa fa-file-pdf-o" aria-hidden="true"></i></a>
                        </p>
                        <p>
                            Acceptance Rate: 28.8%
                        </p>
                </div>

                <h2>Preprints</h2>

                <h3>2024 &nbsp; Why We Build Local Large Language Models: An Observational Analysis from 35 Japanese and Multilingual LLMs</h3>
                <div class="paper-info">
                        <p>
                            Koshiro Saito, Sakae Mizuki, Masanari Ohi, <b>Taishi Nakamura</b>, Taihei Shiotani, Koki Maeda, Youmi Ma, Kakeru Hattori, Kazuki Fujii, Takumi Okamoto, Shigeki Ishida, Hiroya Takamura, Rio Yokota, Naoaki Okazaki
                        </p>
                        <p>
                            <a href="https://arxiv.org/pdf/2412.14471" target="_blank"><i class="fa fa-file-pdf-o" aria-hidden="true"></i></a>
                        </p>
                </div>

                <h3>2024 &nbsp; LLM-jp: A Cross-organizational Project for the Research and Development of Fully Open Japanese LLMs</h3>
                <div class="paper-info">
                        <p>
                            LLM-jp: Akiko Aizawa, Eiji Aramaki, ..., <b>Taishi Nakamura</b>, ..., Koichiro Yoshino (79 authors)
                        </p>
                        <p>
                            <a href="https://arxiv.org/abs/2407.03963" target="_blank"><i class="fa fa-file-pdf-o" aria-hidden="true"></i></a>
                        </p>
                        <p>
                            Note: Authors are listed in alphabetical order.
                        </p>
                </div>

                <h2>Domestic Conference in Japan</h2>

                <h3>NLP 2025 &nbsp; æ–°èè¨˜äº‹ã‹ã‚‰ã¤ãã‚‹ æ™‚äº‹ã¨ç¤¾ä¼šã«å¼·ã„æ—¥æœ¬èªLLM</h3>
                <div class="paper-info">
                        <p>
                        æœéƒ¨ ç¿”, æ°´æœ¨ æ „, è—¤äº• ä¸€å–œ, <b>ä¸­æ‘ æ³°å£«</b>, å¡©è°· æ³°å¹³, æ¤æœ¨ å¿«, æ–°å¦» å·§æœ—, å·ç•‘ è¼, ç”°æ£® ç§€æ˜, Youmi Ma, å‰ç”° èˆªå¸Œ, å¤§äº• è–ä¹Ÿ, é½‹è—¤ å¹¸å²éƒ, å²¡æœ¬ æ‹“å·±, çŸ³ç”° èŒ‚æ¨¹, æ¨ªç”° ç†å¤®, é«˜æ‘ å¤§ä¹Ÿ, å²¡å´ ç›´è¦³
                        </p>
                </div>

                <h3>NLP 2025 &nbsp; Swallowã‚³ãƒ¼ãƒ‘ã‚¹v2: æ•™è‚²çš„ãªæ—¥æœ¬èªã‚¦ã‚§ãƒ–ã‚³ãƒ¼ãƒ‘ã‚¹ã®æ§‹ç¯‰</h3>
                <div class="paper-info">
                        <p>
                            æœéƒ¨ ç¿”, å²¡å´ ç›´è¦³, æ°´æœ¨ æ „, è—¤äº• ä¸€å–œ,  <b>ä¸­æ‘ æ³°å£«</b>, å¤§äº• è–ä¹Ÿ, å¡©è°· æ³°å¹³, é½‹è—¤ å¹¸å²éƒ, Youmi Ma, å‰ç”° èˆªå¸Œ, å²¡æœ¬ æ‹“å·±, çŸ³ç”° èŒ‚æ¨¹, æ¨ªç”° ç†å¤®, é«˜æ‘ å¤§ä¹Ÿ
                        </p>
                </div>

                <h3>NLP 2025 &nbsp; æ¨¡å€£å­¦ç¿’ã«ã‚ˆã‚‹å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã®æŒ‡ç¤ºãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°</h3>
                <div class="paper-info">
                        <p>
                            Youmi Ma, æ°´æœ¨ æ „, è—¤äº• ä¸€å–œ, <b>ä¸­æ‘ æ³°å£«</b>, å¤§äº• è–ä¹Ÿ, å³¶ç”° æ¯”å¥ˆç†, å¡©è°· æ³°å¹³, é½‹è—¤ å¹¸å²éƒ, å‰ç”° èˆªå¸Œ, æœéƒ¨ ç¿”, å²¡æœ¬ æ‹“å·±, çŸ³ç”° èŒ‚æ¨¹, æ¨ªç”° ç†å¤®, é«˜æ‘ å¤§ä¹Ÿ, å²¡å´ ç›´è¦³
                        </p>
                </div>

                <h3>IPSJ 2024 &nbsp; LLMã«æ—¥æœ¬èªãƒ†ã‚­ã‚¹ãƒˆã‚’å­¦ç¿’ã•ã›ã‚‹æ„ç¾©</h3>
                <div class="paper-info">
                        <p>
                            é½‹è—¤ å¹¸å²éƒ, æ°´æœ¨ æ „, å¤§äº• è–ä¹Ÿ, <b>ä¸­æ‘ æ³°å£«</b>, å¡©è°· æ³°å¹³, å‰ç”° èˆªå¸Œ, Ma Youmi, æœéƒ¨ ç¿”, è—¤äº• ä¸€å–œ, å²¡æœ¬ æ‹“å·±, çŸ³ç”° èŒ‚æ¨¹, é«˜æ‘ å¤§ä¹Ÿ, æ¨ªç”° ç†å¤®, å²¡å´ ç›´è¦³
                            <a href="https://sites.google.com/sig-nl.ipsj.or.jp/sig-nl/%E7%A0%94%E7%A9%B6%E7%99%BA%E8%A1%A8%E4%BC%9A/NL261" target="_blank"><i class="fa fa-external-link" aria-hidden="true"></i></a>
                        </p>
                        <span>ğŸ‰ Best Paper Award (6.7%).</span>
                </div>

                <h3>IPSJ 2024 &nbsp; ç¶™ç¶šå­¦ç¿’ã‚’ç”¨ã„ãŸåŠ¹ç‡ã®è‰¯ã„ãƒãƒ«ãƒãƒªãƒ³ã‚¬ãƒ«ãƒ»ãƒãƒ«ãƒã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆãƒ¢ãƒ‡ãƒ«ã®é–‹ç™º</h3>
                <div class="paper-info">
                        <p>
                            <b>ä¸­æ‘æ³°å£«</b>, æ¨ªç”°ç†å¤®
                            <a href="https://www.ipsj.or.jp/event/taikai/86/WEB/data/pdf/5J-01.html" target="_blank"><i class="fa fa-external-link" aria-hidden="true"></i></a>
                        </p>
                </div>

                <h3>NLP 2024 &nbsp; ç¶™ç¶šäº‹å‰å­¦ç¿’ã«ã‚ˆã‚‹æ—¥æœ¬èªã«å¼·ã„å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã®æ§‹ç¯‰</h3>
                <div class="paper-info">
                        <p>
                            è—¤äº•ä¸€å–œâˆ—, <b>ä¸­æ‘æ³°å£«âˆ—</b>, Mengsay Loem, é£¯ç”°å¤§è²´, å¤§äº•è–ä¹Ÿ, æœéƒ¨ç¿”, å¹³äº•ç¿”å¤ª, æ°´æœ¨æ „, æ¨ªç”°ç†å¤®, å²¡å´ç›´è¦³
                            <a href="https://www.anlp.jp/proceedings/annual_meeting/2024/pdf_dir/A8-5.pdf" target="_blank"><i class="fa fa-file-pdf-o" aria-hidden="true"></i></a>
                        </p>
                        <p>
                            âˆ—Equal contribution
                        </p>
                        <p>
                            <a href="https://www.anlp.jp/nlp2024/award.html#outstanding" target="_blank">
                                <span>ğŸ‰ Outstanding Papers (2.0%).</span>
                            </a>
                        </p>
                </div>

                <h3>NLP 2024  &nbsp; å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã®æ—¥æœ¬èªèƒ½åŠ›ã®åŠ¹ç‡çš„ãªå¼·åŒ–: ç¶™ç¶šäº‹å‰å­¦ç¿’ã«ãŠã‘ã‚‹èªå½™æ‹¡å¼µã¨å¯¾è¨³ã‚³ãƒ¼ãƒ‘ã‚¹ã®æ´»ç”¨</h3>
                <div class="paper-info">
                        <p>
                            æ°´æœ¨æ „*, é£¯ç”°å¤§è²´*, è—¤äº•ä¸€å–œ, <b>ä¸­æ‘æ³°å£«</b>, Mengsay Loem, å¤§äº•è–ä¹Ÿ, æœéƒ¨ç¿”, å¹³äº•ç¿”å¤ª, æ¨ªç”°ç†å¤®, å²¡å´ç›´è¦³
                            <a href="https://www.anlp.jp/proceedings/annual_meeting/2024/pdf_dir/A6-4.pdf" target="_blank"><i class="fa fa-file-pdf-o" aria-hidden="true"></i></a>
                        </p>
                        <p>
                            âˆ—Equal contribution
                        </p>
                </div>

                <h3>NLP 2024 &nbsp; Swallowã‚³ãƒ¼ãƒ‘ã‚¹: æ—¥æœ¬èªå¤§è¦æ¨¡ã‚¦ã‚§ãƒ–ã‚³ãƒ¼ãƒ‘ã‚¹</h3>
                <div class="paper-info">
                        <p>
                            å²¡å´ç›´è¦³, æœéƒ¨ç¿”, å¹³äº•ç¿”å¤ª, é£¯ç”°å¤§è²´, å¤§äº•è–ä¹Ÿ, è—¤äº•ä¸€å–œ, <b>ä¸­æ‘æ³°å£«</b>, Mengsay Loem, æ¨ªç”°ç†å¤®, æ°´æœ¨æ „
                            <a href="https://www.anlp.jp/proceedings/annual_meeting/2024/pdf_dir/A6-1.pdf" target="_blank"><i class="fa fa-file-pdf-o" aria-hidden="true"></i></a>
                        </p>
                        <a href="https://www.anlp.jp/nlp2024/award.html#outstanding" target="_blank">
                            <span>ğŸ‰ Outstanding Papers (2.0%).</span>
                        </a>
                </div>

                <h2 id="contact"> Contact </h2>
                <a href="https://twitter.com/Setuna7777_2" target="_blank" rel="noreferrer" class="sns"><img src="https://raw.githubusercontent.com/danielcranney/readme-generator/main/public/icons/socials/twitter.svg" width="32" height="32" /></a>
                <a href="https://www.github.com/Taishi-N324" target="_blank" rel="noreferrer"><img src="https://raw.githubusercontent.com/danielcranney/readme-generator/main/public/icons/socials/github.svg" width="32" height="32" /></a>
                <a href="https://www.linkedin.com/in/taishi-nakamura" target="_blank" rel="noreferrer"><img src="https://raw.githubusercontent.com/danielcranney/readme-generator/main/public/icons/socials/linkedin.svg" width="32" height="32" /></a>                 
                <a href="https://scholar.google.com/citations?hl=en&user=nbPQwgUAAAAJ" target="_blank" rel="noreferrer">
                    <img src="./img/google-scholar.svg" width="32" height="32" alt="Google Scholar" />
                </a>
                <P></p>
                <br>Last updated: March 2025
            </div>
        </div>
    </body>
</html>


